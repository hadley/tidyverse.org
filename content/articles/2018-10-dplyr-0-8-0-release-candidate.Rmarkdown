---
title: dplyr 0.8.0 release candidate
author: Romain FranÃ§ois
date: '2018-10-23'
slug: dplyr-0-8-0-release-candidate
description: > 
  What you need to know about upcoming changes for dplyr 0.8.0.
categories:
  - package
tags:
  - dplyr
  - tidyverse
photo:
  url: https://unsplash.com/photos/kU-WKSyTcp4
  author: Pau Casals
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = T, comment = "#>")
options(tibble.print_min = 4L, tibble.print_max = 4L)
library(dplyr)
# devtools::install_github("rstudio/gt@colorize")
# library(gt)
# show_groups <- function(tbl) {
#   # Get a named list of column labels
#   col_labels <-
#     lapply(names(tbl), function(name) {
#       x <- tbl[[name]]
#       class_x <- class(x)
#       
#       value <- if (class_x == "factor") {
#         paste0("fctr<", paste0(levels(x), collapse = ","), ">")
#       } else {
#         paste0("<", class(x), ">")
#       }
#       paste0(name, " ", value)
#     }) %>%
#     magrittr::set_names(names(tbl))
#   
#   # Create the gt table
#   gt(tbl) %>%
#     cols_label(.list = col_labels) %>%
#     cols_color_gradient_n(
#       column = "x",
#     	breaks = c(0, 3),
#     	colors = c("lightblue", "steelblue")
#     ) %>%
#     cols_color_manual(
#       column = "f1", values = c("a", "b", "c"),
#       colors = c("cornsilk", "bisque", "goldenrod")
#     ) %>% 
#     cols_color_manual(
#       column = "f2", values = c("d", "e", "f"),
#       colors = c("pink", "pink2", "pink3")
#     ) %>% 
#     cols_color_gradient_n(
#       column = "n", breaks = c(0, 1),
#       colors = c("red", "white")
#     ) 
# }
```

A new release of dplyr (0.8.0) is on the horizon, and since it is a major release, we'd love for the 
community to try it out, give us some feedback and [report issues](https://github.com/tidyverse/dplyr/issues)
before we submit to CRAN. This version represents about six months of development, making dplyr more
respectful of factors and less surprising in its evaluation of expressions. 

In this post, we'll highlight the major changes, please see the 
[NEWS](https://github.com/tidyverse/dplyr/blob/master/NEWS.md) for a more 
detailed description of changes. Our formalised process for this release is captured 
in [this issue](https://github.com/tidyverse/dplyr/issues/3931)

```{r, eval = FALSE}
# install.packages("devtools")
devtools::install_github("tidyverse/dplyr")
```

If needed, you can restore the release version by installing from CRAN:

```{r, eval = FALSE}
install.packages("dplyr")
```

# New grouping algorithm

## Group creation

The algorithm behind `group_by()` has been redesigned to better respect factor levels, 
a group is created for each level of the factor, even if there is no data. This 
differs from previous versions of dplyr where groups were only created to 
match the observed data. This closes the epic issue 
[341](https://github.com/tidyverse/dplyr/issues/341) that dates back to 2014. 

Let's illustrate the new algorithm with the [count()](https://dplyr.tidyverse.org/reference/tally.html) 
function:

```{r}
df <- tibble(
  f1 = factor(c("a", "a", "a", "b", "b"), levels = c("a", "b", "c")), 
  f2 = factor(c("d", "e", "d", "e", "f"), levels = c("d", "e", "f")), 
  x  = c(1, 1, 1, 2, 2), 
  y  = 1:5
)
df
df %>% 
  count(f1)
```

Where previous versions of `dplyr` would have created only two groups (for levels `a` and `b`), 
it now creates one group per level, and the group related to the level `c` just happens to be 
empty. 

Groups are still made to match the data on other types of columns:

```{r}
df %>% 
  count(x)
```

Expansion of groups for factors happens at each step of the grouping, so if we group
by `f1` and `f2` we get 9 groups, 

```{r}
df %>% 
  count(f1, f2)
```

When factors and non factors are involved in the grouping, the number of 
groups depends on the order. At each level of grouping, factors are always expanded
to one group per level, but non factors only create groups based on observed data. 

```{r}
df %>% 
  count(f1, x)
```


In this example, we group by `f1` then `x`. At the first layer, grouping on `f1` creates
two groups. Each of these grouops is then subdivided based on the values of the second 
variable `x`. Since `x` is always 1 when `f1` is `a` the group is not 
further divided. 

The last group, associated with the level `c` of the factor `f1` is empty, and 
consequently has no values for the vector `x`. In that case, `group_by()` uses 
`NA`. 

```{r}
df %>% 
  count(x, f1)
```

When we group by `x` then `f1` we initially split the data according to `x` which 
gives 2 groups. Each of these two groups is then further divided in 3 groups, 
i.e. one for each level of `f1`. 

## Group preservation

The grouping structure is more coherently preserved by dplyr verbs, and the notion of 
lazy grouped data frame is now obsolete. We needed lazily grouped data frames 
in previous versions because the verbs did not reconstruct the groups. 

```{r}
df %>% 
  group_by(x, f1) %>% 
  summarise(y = mean(y))
```

The expression `mean(y)` is evaluated for the empty groups as well, and gives 
coherent results with : 

```{r}
mean(numeric())
```

In particular the result of `filter()` preserves the grouping structure of the input 
data frame. 

```{r}
df %>% 
  group_by(x, f1) %>% 
  filter(y < 4)
```

The resulting tibble after the `filter()` call has six groups, the same 
exact groups that were made by `group_by()`. Previous versions of dplyr
would perform an implicit `group_by()` after the filtering, potentially losing
groups. 

Because this is potentially disruptive, `filter()` has gained a `.preserve` argument, 
the default value (`TRUE`) keeps the existing groups, but
when `.preserve` is `FALSE` the data is first filtered and then grouped by:

```{r}
df %>% 
  group_by(x, f1) %>% 
  filter(y < 5, .preserve = FALSE)
```

Note however, that even `.preserve = FALSE` respects the factors that are used as 
grouping variables, in particular `filter( , .preserve = FALSE)` is not a way to 
discard empty groups. The forcats `r emo::ji("package")` may help: 

```{r}
iris %>% 
  group_by(Species) %>% 
  filter(stringr::str_detect(Species, "^v")) %>% 
  ungroup() %>% 
  group_by(Species = forcats::fct_drop(Species))
```

# Changes in filter and slice

Besides changes described previously related to preservation of the grouping structure, 
`filter()` and `slice()` now reorganize the data by groups for performance reasons: 

```{r}
tibble(
  x = c(1, 2, 1, 2, 1), 
  y = c(1, 2, 3, 4, 5)
) %>% 
  group_by(x) %>% 
  filter(y < 5)
```

# Redesigned hybrid evaluation

## What's hybrid evaluation again ?

Hybrid evaluation is used in `summarise()` and `mutate()` to replace 
potential expensive R operations by native C++ code that is group aware. 

```{r}
iris %>% 
  group_by(Species) %>% 
  summarise(Petal.Length = mean(Petal.Length))
```

In the example, the `base::mean()` function is never called because the 
hybrid alternative can directly calculate the mean for each group. Hybrid 
evaluation typically gives better performance because it needs less memory
allocations. 

In this example, a standard evaluation path would need to: 
 - create subsets of the `Petal.Length` column for each group
 - call the `base::mean()` function on each subset, which would also 
   imply a cost for S3 dispatching to the right method
 - collect all results in a new vector
 
In constrast, hybrid evaluation can directly allocate the final 
vector, and calculate all 3 means without having to allocate the subsets. 

## Flaws in previous hybrid

Previous versions of hybrid evaluation relied on folding to 
replace part of the expression by their hybrid result. For example, 
there are hybrid versions of `sum()` and `n()`, so previous 
versions attempted to use them for:

```{r}
iris %>% 
  group_by(Species) %>% 
  summarise(Petal.Length = sum(Petal.Length) / n())
```

The gain of replacing parts of the expression with the result of the
hybrid versions was minimal, and the we had to rely on 
brittle heuristics to try to respect standard R evaluation semantics. 

## New implementation

The new hybrid system is stricter and falls back to standard R evaluation 

when the expression is not entirely recognized. 

The `hybrid_call()` function (subject to change) can be used to test if an expression
would be handled by hybrid or standard evaluation: 

```{r}
iris %>% hybrid_call(mean(Sepal.Length))
iris %>% hybrid_call(sum(Sepal.Length) / n())
iris %>% hybrid_call(+mean(Sepal.Length))
```

Hybrid is very picky about what it can handle, for example `TRUE` and `FALSE` 
are fine for `na.rm=` because they are reserved words that can't be replaced, but 
`T`, `F` or any expression that would resolve to a scalar logical are not: 

```{r}
iris %>% hybrid_call(mean(Sepal.Length, na.rm = TRUE))
iris %>% hybrid_call(mean(Sepal.Length, na.rm = T))
iris %>% hybrid_call(mean(Sepal.Length, na.rm = 1 == 1))
```

The first step of the new hybrid system consists of studying the 
expression and compare it to known expression patterns. If we find an exact
match, then we have all the information we need, and R is never called 
to materialize the result. 

When there is no match, the expression gets evaluated for each group using R standard 
evaluation rules in the data mask: a special environment that makes the 
columns available and uses contextual information for functions such as `n()`
and `row_number()`. 

```{r}
iris %>% 
  group_by(Species) %>% 
  summarise(Petal.Length = sum(Petal.Length) / n())
```

# Performance

When `summarise()` or `mutate()` use expressions that cannot be handled by
hybrid evaluation, they call back to R from the c++ internals for each group. 

This is an expensive operation because the expressions have to be evaluated 
with extra care, traditionally it meant wrapping the expression in an R `tryCatch()` 
before evaluating, but R 3.5.0 has added unwind protection and we exposed that to 
Rcpp. Consequently, the cost of evaluating an R expression carefully is lower 
than before. 

We ran a benchmark of calculating the means of 10 000 small groups with the 
release version of dplyr (0.7.7) and this release candidate with and without 
using the unwind protect feature. 

Just using the `mean()` function would not illustrate the feature, because dplyr would
use hybrid evaluation and never use callbacks to R, so instead we defined a `mean_` 
function that has the same body as `base::mean()`, we also compare this to 
the expression `sum(x) / n()` because it woudld have been handled by 
partial hybrid evaluation in previous versions. 

![](/articles/2018-10-dplyr-0-8-0_files/timings_summarise_mean.jpeg)

The unwind protect feature gives better performance, however 
hybrid evaluation is still very relevant. 

# nest_join

The `nest_join()` function is the newest addition to the join family. 

```{r}
band_members %>% 
  nest_join(band_instruments)
```

A nest join of `x` and `y` returns all rows and all columns from `x`, plus an additional column 
that contains a list of tibbles. Each tibble contains all the rows from `y` that match that row of `x`. 
When there is no match, the list column is a 0-row tibble with the same column names and types as `y`.

`nest_join()` is the most fundamental join since you can recreate the other joins from it: 
 - `inner_join()` is a `nest_join()` plus an `tidyr::unnest()`.
 - `left_join()` is a `nest_join()` plus an `unnest(drop = FALSE)`. 
 - `semi_join()` is a `nest_join()` plus a `filter()` where you check that every element of data has at least one row. 
 - `anti_join()` is a `nest_join()` plus a `filter()` where you check every element has zero rows.

# nest_by

With the new grouping algorithm, dplyr gains the `nest_by()` function, and 
associated `nest_by_at()` and `nest_by_if()` column wise variants. `nest_by()` is 
similar to `tidyr::nest()` but focuses on the columns that define the grouping
rather than the columns that are nested. 

```{r}
iris %>% 
  nest_by(Species)
```

# column wise verbs

Mention `last_col()` and `group_cols()`

# Tidy grouping structure

Previous versions of `dplyr` used a messy set of attributes in grouped
tibbles to keep track of the groups and their indices. This has been 
re-organized into a tibble that can be accessed with the new 
`group_data()` function. 

```{r}
iris %>% 
  group_by(Species) %>% 
  group_data()
```

The first columns of that tibble describe the groups in terms of the 
grouping variables, and the last column (always called `.rows`)
is a list of integer vectors identifying the (one-based) indices of 
each group. 

The related function `group_rows()` gives just that last column. 

```{r}
iris %>% 
  group_by(Species) %>% 
  group_rows()
```
